The complete code base is emulated from the Turbo Topics python code available written by David.M.Blei from pronceston univerity
you can find the code base at : https://github.com/blei-lab/turbotopics
This emulated java code produces the exact same output as that of the python code

Clone this repository and follow the steps as mentioned below

STEPS TO GENERATE TURBOTOPICS:

 STEP 1: Before using this tool to generate TurboTopics, we should generate a set of topics and significant words in those topics using LDA.

 STEP 2: In this step we have to generate required files that will be used to generate TurboTopics. These required files is explained along with the arguments as follows

 <corpus_file>: This is a single file which has a list of lines. Each line is a line of text from the same corpus that was used to generate topics through LDA.

 <vocabulary_file>: This a vocabulary file that lists all unique words that are used in the corpus

 <word_topic_assignemnt_file>: This is a word-to-topic assignment file. This file should be generated using the words from a given topic that was generated by LDA
 The format of the file is as follows
 For every line in the corpus file that was generated in the STEP 1, we generate line which has word-to-topic mapping. ie,
 <line-number> <vocab-index-of-the-word>:<topic-to-which-this-word-is-assigned>. ex:
 Let us assume the vocabulary list to be:
 slow
 and
 study
 wins
 the
 race
 Let us assume the corpus is
 [slow wins]
 [study wins]
 [lose race and wins race]
 Let the word-topic assignment obtained from LDA be
 slow - 1
 and - 3
 study - 2
 wins - 1
 the - 2
 race - 4
 Note: topics are represented as integers (ie, topic0 - 0, topic1 -1) and each word is assigned to a single topic which is the most probable topic for the word
 With all of the above parameters, the assignment file generated will be:
 0 0:1 3:1
 1 2:2 3:1
 2 5:4 1:3 3:1 5:4

 <output_path>: The output path in which the files for each topic will be generated

 <prefix>: The prefix for the output files

 <number_of_topics>: Number of topics to generate. Should be same as the number of topics generated by LDA

 <pvalue>: a value of type Double

 <use_permutaion>: "true" if likelihood ratio score should be generated using permutations

 <min_count>: minimum count of word occurences to be used


 command to run the file,
 enter the "src/main/java/turbotopics" directory and type
 javac LDAtopics.java
 java LDAtopics <corpus_file> <word_topic_assignemnt_file> <vocabulary_file> <output_path> <number_of_topics> <min_count> <pvalue> <use_permutaion> <prefix>

 There is also a convinience script called "execute_tt.sh" which generates the JAR from the code and uses that JAR. To use the convinience script enter "TACIT_TEMP" and type
 ./execute_tt.sh <corpus_file> <word_topic_assignemnt_file> <vocabulary_file> <output_path> <number_of_topics> <min_count> <pvalue> <use_permutaion> <prefix>


STEPS TO GENERATE NGRAMS:

This is the main class that generates NGrams for a given corpus.
Recursively finds collocations for a given corpus.  writes out the marginal counts to a specified file

Steps to be followed to generate NGrams:
 
  <corpus_file>: This is a single file which has a list of lines. Each line is a line of text from every file in the corpus
 
  <output_path>: The output path in which the file containing the NGrams and marginal counts will be generated
 
  <pvalue>: a value of type Double called the precision value
 
  <use_permutaion>: "true" if likelihood ratio score should be generated using permutations, "false" otherwise
 
  <min_count>: minimum count of word occurrences to be considered

  <prefix>: The prefix for the output files
 
  command to run the file
  Enter the "src/main/java/turbotopics" directoruy and type
  javac ComputeNGrams.java
  java ComputeNGrams <corpus_file> <pvalue> <use_permutaion> <output_path> <min_count> <prefix>

  There is also a convinience script called "execute_ngrams.sh" which generates the JAR from the code and uses that JAR. To use the convinience script enter "TACIT_TEMP" and type
   ./execute_ngrams.sh <corpus_file> <pvalue> <use_permutaion> <output_path> <min_count> <prefix>



There are many other convinience scripts that are available.

1. generate_corpus.py :-
This script is used to generate a single corpus file that is required to generate turbotopics or ngrams.
It takes input as a directory path and prints each line from the files in the directory which can be redirected
to a file.
python generate_corpus.py <directory_path_for_corpus_files>  >  <output_path/corpus_file_name>

2. generate_word_assignment.py :-
This script is used to generate the word-topic assignment file that is required to generate turbotopics
It takes input as the the above generated corpus_file and the TACIT-LDA generated  word_weight.txt file
and generates the word-topic assignment
python generate_word_assignment.py <corpus_file> <word_weight_file>  >  <word_topic_assignment_file>

3. generate_vocab.py :-
This script is used to generate vocabulary file that is required to generate turbotopics
It takes the TACIT-LDA generated word_weight.txt file as input and generates a file with list of words (vocabulary)
python generate_vocab.py <word_weight_file>  > <vocabulary_file>

4. compare.py :-
This script is used to compare the output from Turbotopics and Ngrams python code with the Turbotopics and Ngrams java code.
It prints the file name first, and then lists differences if there are any
python compare.py <directory_of_python_generated_files> <directory_of_java_generated_files>


